# -*- coding: utf-8 -*-
"""md simulation using py-geometric.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LdlJ1Q8mN1wI9KUk9pvNqz_wTATjW0jt
"""

!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113

!pip install torch-geometric

import torch
import torch.nn as nn
import torch.optim as optim
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import GCNConv
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np

def generate_data(num_samples):
    configurations = []
    energies = []
    for _ in range(num_samples):
        # Generate random molecular configurations
        configuration = np.random.rand(4, 4)  # Example configuration with 4 molecules with 4features per molecule
        energy = np.random.rand(1)  # Energy associated with each configuration
        configurations.append(configuration)
        energies.append(energy)
    return np.array(configurations), np.array(energies)

samples = 1000
configurations, energies = generate_data(samples)

configurations_train, configurations_test, energies_train, energies_test = train_test_split(configurations, energies, test_size=0.2, random_state=42)

scaler = StandardScaler()
configurations_train_scaled = scaler.fit_transform(configurations_train.reshape(-1, 4)).reshape(configurations_train.shape)
configurations_test_scaled = scaler.transform(configurations_test.reshape(-1, 4)).reshape(configurations_test.shape)

# converting to PyTorch-Geometric Object
class MolecularConfigDataset(torch.utils.data.Dataset):
    def __init__(self, configurations, energies):
        self.configurations = configurations
        self.energies = energies

    def __len__(self):
        return len(self.configurations)

    def __getitem__(self, idx):
        configuration = torch.FloatTensor(self.configurations[idx])
        energy = torch.FloatTensor(self.energies[idx])
        return Data(x=configuration, y=energy)

train_dataset = MolecularConfigDataset(configurations_train_scaled, energies_train)
test_dataset = MolecularConfigDataset(configurations_test_scaled, energies_test)

train_dataset

train_loader = DataLoader(train_dataset, batch_size=32)
test_loader = DataLoader(test_dataset, batch_size=32)

train_loader

#GCN Model
class GCN(nn.Module):
    def __init__(self):
        super(GCN, self).__init__()
        self.conv1 = GCNConv(4, 64)
        self.conv2 = GCNConv(64, 32)
        self.fc = nn.Linear(32, 1)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index

        x = self.conv1(x, edge_index)
        x = torch.relu(x)
        x = self.conv2(x, edge_index)
        x = torch.relu(x)

        # Global pooling to aggregate node features / AGGREGATION FUNCTION
        x = torch.mean(x, dim=0, keepdim=True)

        x = self.fc(x)
        return x

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = GCN().to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

model.train()
for epoch in range(10):
    running_loss = 0.0
    for data in train_loader:
        data = data.to(device)
        optimizer.zero_grad()
        outputs = model(data)
        loss = criterion(outputs, data.y)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * data.num_graphs
    print(f"Epoch {epoch+1}, Loss: {running_loss / len(train_dataset)}")

model.eval()
test_loss = 0.0
with torch.no_grad():
    for data in test_loader:
        data = data.to(device)
        outputs = model(data)
        test_loss += criterion(outputs, data.y).item() * data.num_graphs
print(f"Test Loss: {test_loss / len(test_dataset)}")